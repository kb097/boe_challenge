{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andy Haldane Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Speeches as Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction\\nI am delighted to be speaking at this “Engaging Business” Summit, at such a critical time for business, for workers and for the wider economy. The focus of today, and the excellent background report, is happiness in the workplace. This is an issue in which everyone has a stake. It is particularly pertinent with many people having had to adapt their ways of working as a result of the Covid crisis. Indeed, this year may well have seen the largest shift in working practices ever seen, certainly the largest in modern times.\\n\\nThat begs a host of questions about the impact of these changes in working practices on workers, businesses, communities and the wider economy. For economists like me, it raises questions about the impact on productivity and output in the workplace. As arid as'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_path = Path('speeches')\n",
    "\n",
    "speeches = []\n",
    "for file in os.listdir(speeches_path):\n",
    "    if file.endswith('.txt'):\n",
    "        with open(speeches_path / file) as f:\n",
    "            speeches.append(f.read())\n",
    "            \n",
    "speeches[0][:800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'introduction i am delighted to be speaking at this engaging business summit at such a critical time for business for workers and for the wider economy the focus of today and the excellent background report is happiness in the workplace this is an issue in which everyone has a stake it is particularly pertinent with many people having had to adapt their ways of working as a result of the covid crisis indeed this year may well have seen the largest shift in working practices ever seen certainly the largest in modern times that begs a host of questions about the impact of these changes in working practices on workers businesses communities and the wider economy for economists like me it raises questions about the impact on productivity and output in the workplace as arid as these concepts can'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, speech in enumerate(speeches):\n",
    "    speech = speech.replace('\\n', ' ')  # replace newline characters with spaces\n",
    "    speech.replace(\"'\", '')  # remove apostrophes\n",
    "    speech = re.sub(r'.footnote\\[[0-9]+\\]', '', speech)  # remove .footnote[x] text\n",
    "    speech = ''.join(filter(lambda x: x.isalpha() or x==' ', speech)) # remove non-alphabetic characters\n",
    "    speech = speech.lower()   # convert text to lower case\n",
    "    speech = re.sub(r' +', ' ', speech).strip()  # remove multiple and leading spaces\n",
    "    speeches[i] = speech\n",
    "\n",
    "speeches[0][:800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> In order to try and extract information about the topics discussed we start by looking at the frequency of all words used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 189),\n",
       " ('of', 131),\n",
       " ('to', 99),\n",
       " ('and', 95),\n",
       " ('in', 79),\n",
       " ('a', 62),\n",
       " ('is', 55),\n",
       " ('homeworking', 45),\n",
       " ('for', 40),\n",
       " ('working', 40),\n",
       " ('that', 40),\n",
       " ('i', 34),\n",
       " ('as', 33),\n",
       " ('has', 31),\n",
       " ('these', 30),\n",
       " ('productivity', 30),\n",
       " ('from', 30),\n",
       " ('by', 28),\n",
       " ('have', 27),\n",
       " ('be', 26)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(speeches[0].split(' '))\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> We can see that some words like \"the\" are frequent but not very informative. In order to improve the analysis it is best to remove such \"stopwords\" and is done so here by cross-referencing with a list of known stopwords imported from the Python library spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('homeworking', 45),\n",
       " ('working', 40),\n",
       " ('productivity', 30),\n",
       " ('time', 19),\n",
       " ('work', 19),\n",
       " ('people', 18),\n",
       " ('workers', 17),\n",
       " ('home', 17),\n",
       " ('covid', 14),\n",
       " ('wellbeing', 14),\n",
       " ('effects', 14),\n",
       " ('crisis', 13),\n",
       " ('social', 12),\n",
       " ('office', 12),\n",
       " ('capital', 12),\n",
       " ('studies', 11),\n",
       " ('creativity', 11),\n",
       " ('shift', 10),\n",
       " ('different', 10),\n",
       " ('evidence', 10)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_counts = Counter(list(filter(lambda x: x not in STOP_WORDS, speeches[0].split(' '))))\n",
    "new_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> The results of this analysis seem to show evidence that the focus of this speech is on homeworking due to covid and the effects this will have on productivity, wellbeing and creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Applying this same approach to his final speech on 30th June 2021 gives the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bank', 111),\n",
       " ('financial', 84),\n",
       " ('banks', 80),\n",
       " ('policy', 65),\n",
       " ('monetary', 63),\n",
       " ('central', 55),\n",
       " ('uk', 48),\n",
       " ('public', 35),\n",
       " ('crisis', 33),\n",
       " ('time', 32),\n",
       " ('new', 31),\n",
       " ('inflation', 30),\n",
       " ('years', 29),\n",
       " ('economy', 28),\n",
       " ('stability', 26),\n",
       " ('system', 24),\n",
       " ('guidance', 21),\n",
       " ('risk', 17),\n",
       " ('past', 16),\n",
       " ('s', 16),\n",
       " ('global', 16),\n",
       " ('good', 15),\n",
       " ('crises', 15),\n",
       " ('forward', 15),\n",
       " ('international', 15),\n",
       " ('banking', 15),\n",
       " ('expectations', 14),\n",
       " ('far', 14),\n",
       " ('better', 13),\n",
       " ('interest', 13)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_counts = Counter(list(filter(lambda x: x not in STOP_WORDS, speeches[1].split(' '))))\n",
    "new_counts.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Here the results aren't as clear but it seems like the topics of global inflation and economic stability were discuessed. However, with this speech a better approach is probably needed to make sure of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Another approach that may work better is a dictionary based approach that counts the usage of pre-determined key words or phrases that are associated with potential risks that could be discussed. This has an obvious disadvantage in that it requires the possible risks to be known beforehand but could be a good way to categorise speeches with risks that occur resasonably frequently or can be forseen such as high unemployment rates.\n",
    "    \n",
    "One flaw with these word count approaches is that they indiscriminantly show all topics discussed which can be a problem in speeches such as Andy Haldane's final speech where a large portion is spent discussing his early career at Bank of England. A potential fix for this is to filter out paragraphs that don't have enough usages of negative words such as \"risk\" and \"crisis\" using either a dictionary of such words or a sentiment analysis algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Another flaw is that certain words or topics are likely to be discussed in all speeches. In order to fix this one option is to look at the distribution of words across all the speeches together and place greater importance on those that are more concentrated in particular speeches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
